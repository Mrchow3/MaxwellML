{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning RNNs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZJcBRPM2HEm",
        "colab_type": "text"
      },
      "source": [
        "#Intro to RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BHHTWo9RLMo",
        "colab_type": "text"
      },
      "source": [
        "DNNs often have a dificult time processing time series data as the input data needs to be inputted as a single data point, or the DNN needs to be able to reference previous time points while fitting data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pzPEgPVSFjd",
        "colab_type": "text"
      },
      "source": [
        "Furthermore, the problem of disappearing gradients occurs when sigmoid activations calculate a small gradient as a result of several million/billion parameters across several layers (Also another reason why relu is preferred). This gradient becomes so small that the model would require an arbitrarily large amount of epochs to train since backpropagating an arbitrarily small gradient would have little impact on the activations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSYApmmJRfm6",
        "colab_type": "text"
      },
      "source": [
        "RNNs fix this problem by deciding what previous calculations should be used to influence calculations while the model is fitting. Specific layers perform this task and then feed the information into a set of classifier layers that send an output. This perserves time series data and the allows prior calculations to influence future ones in order to prevent small gradient updates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Olr6cp2R7O",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://lh3.googleusercontent.com/proxy/qC7bP_rNp8AbPCR2gKYAbeVQqo0TZW5dELa1kRud2E0ZkKOs-m7sdTR6613A8emm__t3pYrPcy0S2-rPPma9JYLwM_YXj7ucWj0Y2ta0QIw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvUo8CNZR0WX",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/3032/1*yBXV9o5q7L_CvY7quJt3WQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0dP1UfgR3Hi",
        "colab_type": "text"
      },
      "source": [
        "In each RNN layer, data is fed into the layer and based on the weights of that layer, the RNN chooses what to forget, and what to add onto a future input. Calculating what to add and what to forget is looped throughout every datapoint similar to a for loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao-lttUuS6ja",
        "colab_type": "text"
      },
      "source": [
        "Above are examples of state of the art RNN layers that are used everywhere. The activation layers are the layers choosing what to \"forget\" and the concatenation are the layers choosing what to \"add to the future data\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHl6epHZUQKK",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FxlfYawUSfA",
        "colab_type": "text"
      },
      "source": [
        "Note that this model doesn't have a loss function or weights. The weights are imbeded in the multiplication and addition sign, gradient descent propagates an update the same way as regular network: (Also note that the derivative of tanh is more expensive than the sigmoid so relu is often subsituted for one of these activations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQw2MyxeViPw",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://2.bp.blogspot.com/-ZxJ87cWjPJ8/TtLtwqv0hCI/AAAAAAAAAV0/9FYqcxJ6dNY/s1600/gradient+descent+algorithm+OLS.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Vl8otTVobO",
        "colab_type": "text"
      },
      "source": [
        "Except the partial derivative is calculated every activation layer and the gradient of the cost function is needed to calculate the loss in a particular direction. Thus the RNN layer needs to propagate n partial derivatives (where n is # of features) to calculate a change in the weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUWGkiWlXblm",
        "colab_type": "text"
      },
      "source": [
        "RNNs are often used for NLP (Natural Language Processing) because temporal and spatial hierarchies are preserved. Typical algorithms take the amount of words and the type of words, but do not take in account their position and the time elapsed from a word. This allows RNNs to stand out because they account for these flaws and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-EFbga6WqjN",
        "colab_type": "text"
      },
      "source": [
        "Keras handles lstms and grus but data transformation is still needed in order to use these layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_DriTUyaO7o",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing data for RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2znr5lVYgBrx",
        "colab_type": "text"
      },
      "source": [
        "In order to process words, they are \"Tokenized\" or split into several tokens: (Each sentence has its own tensor and contains each tokenized word). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzgq5a6zgPa2",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://freecontent.manning.com/wp-content/uploads/Chollet_DLfT_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsVIjWTWgjsp",
        "colab_type": "text"
      },
      "source": [
        "Sentence tensor:\n",
        "\n",
        "\n",
        "```\n",
        "[[\"The\",\"Cat\",\"Sat\",\"On\",\"The\",\"Mat\",\".\"], [\"The\",\"Cat\",\"Took\",\"The\",\"Hat\",\".\"]] #Then each word is tokenized\n",
        "```\n",
        "\n",
        "\n",
        "Also note that words are case sensitive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-tFzdaTaSP1",
        "colab_type": "text"
      },
      "source": [
        "Typically words are one hot encoded by letter and then concantenated to a sentence tensor and a row's length = largest word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnMJzyEkbn0e",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://assets.website-files.com/5ac6b7f2924c656f2b13a88c/5b873726ab29dbea4f33ae80_Screen%20Shot%202018-08-27%20at%202.32.03%20PM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E2U0Ih8hgrt",
        "colab_type": "text"
      },
      "source": [
        "If this method is not used, a word dictionary where each word is assigned an index and then each word is one hot encoded. This one hot encoded vector is then kept in the word dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45fyB-L0b7Va",
        "colab_type": "text"
      },
      "source": [
        "Note that a one hot encoded word tensor would be absolutely huge because words such as \"The\" would need to be padded in order to account for a row. Instead, word vectors are used. Word vectors are essentially encoded words but instead of encoding each letter, the entire word is assigned to a vector. This vector is also calculated in relation to other words: (This creates a relation between words allowing for better predictive power)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWcuQX6SdRLU",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.ytimg.com/vi/wvsE8jm1GzE/maxresdefault.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw2CEdkedT8f",
        "colab_type": "text"
      },
      "source": [
        "Each MNIST number is clustered in relation to eachother (There are several false positives due to picture similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Z10akbdgZG",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/612/1*j-ZDkqDKmkH7XVkE0MckUQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFGJ7aE1drtA",
        "colab_type": "text"
      },
      "source": [
        "Distances between vectors indicate relation and vectors can be concantenated to produce a new vector. This is super useful as you can derive relations from other vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOUMYc-zeg5D",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/ZackAkil/nlp-using-word-vectors/master/images/cosine1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r3zjXXXezYl",
        "colab_type": "text"
      },
      "source": [
        "Word vectors have to be learned as relations are not magically produced from nowhere. This process is done in tandem with training a model. Since learning word vectors are similar to training a model, word vectors can be loaded in from an external dataset (Word2Vec is a popular dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ8c2wV6iDUg",
        "colab_type": "text"
      },
      "source": [
        "###Code for preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbD7PsLbaR9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=1000) #Given a dataset, only considers the top 1000 most common words\n",
        "tokenizer.fit_on_texts(samples) #Creates a word dictionary/index \n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(samples) #Creates tensor of integer indicies from dictionary ([1,2,3,4,5],[2,3,4,1,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlWX3PUgjSCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary') #Raw one hot encoding "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keQkR_YYjHjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index)) #Recovers word indicies and returns dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7KdnUDVnh1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "x_test = preprocessing.sequence.pad_sequences(sequences, maxlen=maxlen) #Padding a tensor incase data samples are not equal size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luMiqVJBW8wb",
        "colab_type": "text"
      },
      "source": [
        "#Project description:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDNTSekcXAKl",
        "colab_type": "text"
      },
      "source": [
        "The IMDB dataset (a common ML dataset) will be used in conjunction with keras to predict if a movie review is positive or negative. Note that this model can be carried over to other problems as the use of words include a spatial hierarchy (position of words matter). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txLf59l-ZtzY",
        "colab_type": "text"
      },
      "source": [
        "Processing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F54QCv3ql6ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pickling the dataset, needs to run only once\n",
        "'''\n",
        "############# === Processing data only needs to run once properly === #############\n",
        "import os, shutil  \n",
        "from tqdm.auto import tqdm as tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Goal: label and organize data\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "categories = [\"neg\",\"pos\"]\n",
        "data_dir_origin = '/content/drive/My Drive/Datasets/imdb_ds/{}'\n",
        "for label in categories:\n",
        "  data_dir = '/content/drive/My Drive/Datasets/imdb_ds/{}'.format(label)\n",
        "  for file_name in tqdm(os.listdir(data_dir)):\n",
        "    print(file_name)\n",
        "    #print(file_name[-4:])\n",
        "\n",
        "    try:\n",
        "\n",
        "      if file_name[-4:] == '.txt':\n",
        "        f = open(os.path.join(data_dir,file_name)) #Opening and reading the file object.\n",
        "        features.append(f.read()) #Appending the data read from the read object.\n",
        "        f.close()\n",
        "      if label == 'neg':\n",
        "        labels.append(label)\n",
        "      if label == 'pos':\n",
        "        labels.append(label)\n",
        "\n",
        "    except Exception as e:\n",
        "      #Exception is a general exception it is not defined it will give whatever the error was\n",
        "      print(\"Something went wrong\", e)\n",
        "\n",
        "import pickle as pic\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Datasets/Pickles'\n",
        " \n",
        "pickle_file = open(DATA_PATH + '/features_imdb.pickle',\"wb\") \n",
        " \n",
        "pic.dump(features, pickle_file)\n",
        "pickle_file.close()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Datasets/Pickles'\n",
        "  \n",
        "pickle_file = open(DATA_PATH + '/labels_imdb.pickle',\"wb\") \n",
        " \n",
        "pickle.dump(labels, pickle_file)\n",
        "pickle_file.close()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBmWtf1sW_0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "176ba39b-0d89-4b43-b278-d3a3e9deee68"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Datasets and Pickles/Pickles_Old'\n",
        "infile1 = open(DATA_PATH + '/features_imdb.pickle',\"rb\")\n",
        "features = pickle.load(infile1)\n",
        "infile = open(DATA_PATH + '/labels_imdb.pickle',\"rb\")\n",
        "labels = pickle.load(infile)\n",
        "\n",
        "features = np.asarray(features)\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "if \"neg\" and \"pos\" in labels:\n",
        "  print(\"Data checked\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data checked\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGXOsXZ1mil7",
        "colab_type": "text"
      },
      "source": [
        "Encoding the outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqk_wKPxRtEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6dc5fc9e-73aa-44da-87ce-b00c3edaf2db"
      },
      "source": [
        "print(len(labels))\n",
        "for i, j in enumerate(labels):\n",
        "  try:\n",
        "    if j == \"neg\":\n",
        "      labels[i] = 0\n",
        "    if j == \"pos\":\n",
        "      labels[i] = 1\n",
        "  except Exception as e:\n",
        "    pass #Do not do this in production model\n",
        "\n",
        "\n",
        "print(labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17263\n",
            "['0' '0' '0' ... '1' '1' '1']\n",
            "17263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ZIghZWZydz",
        "colab_type": "text"
      },
      "source": [
        "Here I will be using ```tensorflow.keras.preprocessing``` to process data before feeding it into the RNN as well as an embedding layer to learn word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kORaUbF9QaDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "\n",
        "max_features = 10000 #Using only 10000 most frequent words\n",
        "maxlen = 500 #limits all of the reviews to 500 words\n",
        "batch_size = 32\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_features)\n",
        "tokenizer.fit_on_texts(features)\n",
        "sequences = tokenizer.texts_to_sequences(features)\n",
        "\n",
        "data = sequence.pad_sequences(sequences, maxlen = maxlen) #Cutting down to 500 words\n",
        "\n",
        "#The following code creates indicies for a combined tensor, randomizes the index, and then assigns the feature and label to the index aligning the data.\n",
        "#This will only work if the features and labels are matching beforehand.\n",
        "indicies = np.arange(data.shape[0])\n",
        "np.random.shuffle(indicies)\n",
        "data = data[indicies]\n",
        "labels = labels[indicies]\n",
        "np.asarray(labels)\n",
        "\n",
        "X_data = data[0:500]\n",
        "y_data = labels[0:500]\n",
        "\n",
        "X_test = data[500:2000]\n",
        "y_test = labels[500:2000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HHfBR7iZw1P",
        "colab_type": "text"
      },
      "source": [
        "Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNdKPbUfYyCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Dropout,GRU,Embedding\n",
        "\n",
        "################################## === Reccurent layers === ##################################\n",
        "model = Sequential()\n",
        "\n",
        "#Do not insert dropout\n",
        "model.add(Embedding(max_features , 32))\n",
        "model.add(GRU(32,\n",
        "              dropout = 0.1,\n",
        "              return_sequences = True, #Returns each output at the end of a reccurent loop\n",
        "              ))\n",
        "#Do not insert dropout\n",
        "model.add(GRU(64,\n",
        "              dropout = 0.1,\n",
        "              recurrent_dropout = 0.5)) #Specified temporal dropout mask\n",
        "\n",
        "################################## === Model === ##################################\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(16,\n",
        "                activation = 'relu',\n",
        "                kernel_regularizer=regularizers.l2(0.01)\n",
        "                ))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1,activation = \"sigmoid\"))\n",
        "################################## === Compile === ##################################\n",
        "\n",
        "model.compile(optimizer = 'rmsprop',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['acc']\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NTEJkliv_fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9607b0c5-dc5b-4c0f-b7de-266c5c7dfc58"
      },
      "source": [
        "history = model.fit(X_data,y_data,\n",
        "                    epochs = 100,\n",
        "                    batch_size = 128,\n",
        "                    validation_split = 0.3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 350 samples, validate on 150 samples\n",
            "Epoch 1/100\n",
            "350/350 [==============================] - 6s 17ms/sample - loss: 0.9231 - acc: 0.6486 - val_loss: 0.8913 - val_acc: 0.6867\n",
            "Epoch 2/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.8594 - acc: 0.7371 - val_loss: 0.8474 - val_acc: 0.6867\n",
            "Epoch 3/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.7919 - acc: 0.7371 - val_loss: 0.8328 - val_acc: 0.6867\n",
            "Epoch 4/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.7673 - acc: 0.7371 - val_loss: 0.8249 - val_acc: 0.6867\n",
            "Epoch 5/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.7080 - acc: 0.7371 - val_loss: 0.8098 - val_acc: 0.6867\n",
            "Epoch 6/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.6769 - acc: 0.7371 - val_loss: 0.7991 - val_acc: 0.6867\n",
            "Epoch 7/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.6182 - acc: 0.7429 - val_loss: 0.8063 - val_acc: 0.6867\n",
            "Epoch 8/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.5390 - acc: 0.8000 - val_loss: 0.8478 - val_acc: 0.6867\n",
            "Epoch 9/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.4739 - acc: 0.8857 - val_loss: 0.7990 - val_acc: 0.7267\n",
            "Epoch 10/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.4085 - acc: 0.9600 - val_loss: 0.8027 - val_acc: 0.7000\n",
            "Epoch 11/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.3564 - acc: 0.9943 - val_loss: 1.0269 - val_acc: 0.7133\n",
            "Epoch 12/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.3022 - acc: 0.9943 - val_loss: 1.1585 - val_acc: 0.6933\n",
            "Epoch 13/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.2524 - acc: 1.0000 - val_loss: 1.0718 - val_acc: 0.7000\n",
            "Epoch 14/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.2281 - acc: 0.9943 - val_loss: 0.8705 - val_acc: 0.6200\n",
            "Epoch 15/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.2219 - acc: 0.9914 - val_loss: 1.1591 - val_acc: 0.7200\n",
            "Epoch 16/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1914 - acc: 0.9971 - val_loss: 1.1043 - val_acc: 0.7000\n",
            "Epoch 17/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1757 - acc: 1.0000 - val_loss: 1.1382 - val_acc: 0.6867\n",
            "Epoch 18/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1685 - acc: 1.0000 - val_loss: 1.2158 - val_acc: 0.7067\n",
            "Epoch 19/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1570 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.6933\n",
            "Epoch 20/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1468 - acc: 1.0000 - val_loss: 1.2721 - val_acc: 0.6933\n",
            "Epoch 21/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1419 - acc: 1.0000 - val_loss: 1.2893 - val_acc: 0.6933\n",
            "Epoch 22/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1366 - acc: 1.0000 - val_loss: 1.3799 - val_acc: 0.7067\n",
            "Epoch 23/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1368 - acc: 0.9971 - val_loss: 1.2113 - val_acc: 0.6800\n",
            "Epoch 24/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1271 - acc: 1.0000 - val_loss: 1.2829 - val_acc: 0.6867\n",
            "Epoch 25/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1205 - acc: 1.0000 - val_loss: 1.3778 - val_acc: 0.7067\n",
            "Epoch 26/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1162 - acc: 1.0000 - val_loss: 1.3996 - val_acc: 0.6933\n",
            "Epoch 27/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.1108 - acc: 1.0000 - val_loss: 1.6437 - val_acc: 0.7067\n",
            "Epoch 28/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1067 - acc: 1.0000 - val_loss: 1.5480 - val_acc: 0.7000\n",
            "Epoch 29/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.1007 - acc: 1.0000 - val_loss: 1.4068 - val_acc: 0.6800\n",
            "Epoch 30/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0969 - acc: 1.0000 - val_loss: 1.5023 - val_acc: 0.6933\n",
            "Epoch 31/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0925 - acc: 1.0000 - val_loss: 1.5785 - val_acc: 0.6933\n",
            "Epoch 32/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0907 - acc: 1.0000 - val_loss: 1.5407 - val_acc: 0.7200\n",
            "Epoch 33/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0837 - acc: 1.0000 - val_loss: 1.6052 - val_acc: 0.7133\n",
            "Epoch 34/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.0806 - acc: 1.0000 - val_loss: 1.6732 - val_acc: 0.7133\n",
            "Epoch 35/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0776 - acc: 1.0000 - val_loss: 1.6861 - val_acc: 0.7200\n",
            "Epoch 36/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0741 - acc: 1.0000 - val_loss: 1.7423 - val_acc: 0.7267\n",
            "Epoch 37/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0828 - acc: 0.9943 - val_loss: 2.1827 - val_acc: 0.7200\n",
            "Epoch 38/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0679 - acc: 1.0000 - val_loss: 1.8406 - val_acc: 0.7000\n",
            "Epoch 39/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0650 - acc: 1.0000 - val_loss: 1.8230 - val_acc: 0.7000\n",
            "Epoch 40/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0619 - acc: 1.0000 - val_loss: 1.8455 - val_acc: 0.7067\n",
            "Epoch 41/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0600 - acc: 1.0000 - val_loss: 1.9430 - val_acc: 0.7000\n",
            "Epoch 42/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 1.9734 - val_acc: 0.7000\n",
            "Epoch 43/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 1.9931 - val_acc: 0.7000\n",
            "Epoch 44/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 1.9284 - val_acc: 0.7000\n",
            "Epoch 45/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0493 - acc: 1.0000 - val_loss: 1.9558 - val_acc: 0.7000\n",
            "Epoch 46/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 1.9603 - val_acc: 0.6933\n",
            "Epoch 47/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 2.0153 - val_acc: 0.7067\n",
            "Epoch 48/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 1.9560 - val_acc: 0.7133\n",
            "Epoch 49/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0401 - acc: 1.0000 - val_loss: 1.9790 - val_acc: 0.7133\n",
            "Epoch 50/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0390 - acc: 1.0000 - val_loss: 2.0775 - val_acc: 0.7200\n",
            "Epoch 51/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 2.0391 - val_acc: 0.7200\n",
            "Epoch 52/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 2.0570 - val_acc: 0.7067\n",
            "Epoch 53/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 1.9635 - val_acc: 0.7200\n",
            "Epoch 54/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 2.0405 - val_acc: 0.7133\n",
            "Epoch 55/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 2.3532 - val_acc: 0.6867\n",
            "Epoch 56/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.4317 - acc: 0.9314 - val_loss: 1.4305 - val_acc: 0.7133\n",
            "Epoch 57/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.0387 - acc: 0.9971 - val_loss: 1.4326 - val_acc: 0.7067\n",
            "Epoch 58/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 1.4424 - val_acc: 0.7133\n",
            "Epoch 59/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 1.4530 - val_acc: 0.7000\n",
            "Epoch 60/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 1.5151 - val_acc: 0.6933\n",
            "Epoch 61/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 1.6214 - val_acc: 0.6867\n",
            "Epoch 62/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 1.6459 - val_acc: 0.6867\n",
            "Epoch 63/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 1.6537 - val_acc: 0.6933\n",
            "Epoch 64/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 1.6748 - val_acc: 0.6933\n",
            "Epoch 65/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 1.6626 - val_acc: 0.7000\n",
            "Epoch 66/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 1.6897 - val_acc: 0.7000\n",
            "Epoch 67/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 1.7102 - val_acc: 0.7000\n",
            "Epoch 68/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 1.7286 - val_acc: 0.7000\n",
            "Epoch 69/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 1.7217 - val_acc: 0.7000\n",
            "Epoch 70/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 1.7293 - val_acc: 0.7067\n",
            "Epoch 71/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 1.7420 - val_acc: 0.7000\n",
            "Epoch 72/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 1.7428 - val_acc: 0.7067\n",
            "Epoch 73/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 1.7558 - val_acc: 0.7067\n",
            "Epoch 74/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 1.7680 - val_acc: 0.7067\n",
            "Epoch 75/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 1.7697 - val_acc: 0.7067\n",
            "Epoch 76/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 1.7585 - val_acc: 0.7067\n",
            "Epoch 77/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 1.7740 - val_acc: 0.7000\n",
            "Epoch 78/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 1.8189 - val_acc: 0.7000\n",
            "Epoch 79/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 2.0012 - val_acc: 0.7200\n",
            "Epoch 80/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 1.9636 - val_acc: 0.7267\n",
            "Epoch 81/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 1.9866 - val_acc: 0.7267\n",
            "Epoch 82/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.9459 - val_acc: 0.7200\n",
            "Epoch 83/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 1.9112 - val_acc: 0.7333\n",
            "Epoch 84/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.9041 - val_acc: 0.7333\n",
            "Epoch 85/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 2.1266 - val_acc: 0.7133\n",
            "Epoch 86/100\n",
            "350/350 [==============================] - 4s 11ms/sample - loss: 0.0406 - acc: 0.9943 - val_loss: 1.6428 - val_acc: 0.7000\n",
            "Epoch 87/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.7030 - val_acc: 0.6933\n",
            "Epoch 88/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 1.7006 - val_acc: 0.6800\n",
            "Epoch 89/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.7511 - val_acc: 0.6667\n",
            "Epoch 90/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.8098 - val_acc: 0.6667\n",
            "Epoch 91/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.8696 - val_acc: 0.6667\n",
            "Epoch 92/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.8677 - val_acc: 0.6733\n",
            "Epoch 93/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.8907 - val_acc: 0.6733\n",
            "Epoch 94/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.8979 - val_acc: 0.6733\n",
            "Epoch 95/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.9146 - val_acc: 0.6667\n",
            "Epoch 96/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.8939 - val_acc: 0.6733\n",
            "Epoch 97/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.9174 - val_acc: 0.6667\n",
            "Epoch 98/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.9513 - val_acc: 0.6667\n",
            "Epoch 99/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.9662 - val_acc: 0.6667\n",
            "Epoch 100/100\n",
            "350/350 [==============================] - 4s 12ms/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 2.0232 - val_acc: 0.6667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdnJrrnKwfTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "006fea43-e65d-4071-db8c-657aa4ad212a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = [i for i in range(0,100)]\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs Epochs\")\n",
        "plt.plot(epochs,loss)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9475136f60>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqSr2It05i0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "4748a849-637d-45a8-8508-60130720fc6a"
      },
      "source": [
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Val_Loss\")\n",
        "plt.title(\"Val_Loss vs Epochs\")\n",
        "plt.plot(epochs,val_loss)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f94746cb7f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwnN5S1b1oEf",
        "colab_type": "text"
      },
      "source": [
        "As seen above, the model quickly overfits. This is in part due to the word embedding layer not being fully representing the entire dataset due to the data not being cleaned. The val_loss being so high makes this model unusable, but it can be drastically improved using an NLP model, NLP processing, and an imported word vector lib (Word2Vec)."
      ]
    }
  ]
}